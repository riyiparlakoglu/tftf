{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zVncIXUbTgKm2nAG7uIG8CnqEzMetXAm",
      "authorship_tag": "ABX9TyNfebwXwG2xvpWn6qXpZf3s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riyiparlakoglu/tftf/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AkX-MRlklmMz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 224\n",
        "target_size = (image_size, image_size)\n",
        "input_shape = (image_size, image_size, 3)\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "96f3rT-ZluCY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"../content/drive/MyDrive/yenidata\"\n",
        "train_dir = os.path.join(base_dir,\"train\")\n",
        "test_dir = os.path.join(base_dir,\"test\")\n",
        "predict_dir = os.path.join(base_dir, \"predict\")"
      ],
      "metadata": {
        "id": "3p-VUXEAlxAR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0,\n",
        "                                                             shear_range = 0.2,\n",
        "                                                             zoom_range = 0.2,\n",
        "                                                             width_shift_range = 0.2,\n",
        "                                                             height_shift_range = 0.2,\n",
        "                                                             fill_mode=\"nearest\")\n",
        "\n",
        "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0)"
      ],
      "metadata": {
        "id": "c47iCPGDl1sI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size = (image_size, image_size),\n",
        "                                              \n",
        "                                               class_mode = \"categorical\")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size = (image_size, image_size),\n",
        "                                            \n",
        "                                             class_mode = \"categorical\")\n"
      ],
      "metadata": {
        "id": "uvZk-HGzl4Et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b804369-45ef-4494-f9c1-6151134f855d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 120 images belonging to 3 classes.\n",
            "Found 30 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = list(train_data.class_indices.keys())\n",
        "print(train_data.class_indices)"
      ],
      "metadata": {
        "id": "VjM_qHuBqC65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c3e1d6-d05f-4a67-d783-01d06dfb95ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bac': 0, 'healthy': 1, 'late': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('class_indices.json','w') as f:\n",
        "  json.dump(train_data.class_indices, f)\n",
        "\n",
        "from IPython.display import FileLink\n",
        "FileLink(r'class_indices.json')"
      ],
      "metadata": {
        "id": "At6NyTVBqHvH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea1ab60b-6745-48e1-be2e-ea160977d670"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/content/class_indices.json"
            ],
            "text/html": [
              "<a href='class_indices.json' target='_blank'>class_indices.json</a><br>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNet(weights = \"imagenet\",\n",
        "                                             include_top = False,\n",
        "                                             input_shape = input_shape)\n",
        "\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "bTePQqnOqJ66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a26c3a-731e-4206-9415-1834035004a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n",
            "17235968/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape = input_shape)\n",
        "\n",
        "x = base_model(inputs, training = False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(len(categories), \n",
        "                          activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs = inputs, \n",
        "                    outputs = x, \n",
        "                    name=\"LeafDisease_MobileNet\")"
      ],
      "metadata": {
        "id": "imSgI9DlqMQV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "model.compile(optimizer = optimizer,\n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy(), \n",
        "                       'accuracy'])"
      ],
      "metadata": {
        "id": "HaIIkkQrqOQJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('plant_disease_2')"
      ],
      "metadata": {
        "id": "3FNxnH_9sHCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3171a30-fd22-49f7-d03e-6c81dbf1aeb0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: plant_disease_2/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data,\n",
        "                    validation_data=test_data,\n",
        "                    epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU_4XrJEqQJZ",
        "outputId": "9a969b94-dec5-492a-9bc8-d7e5eede9360"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 12s 3s/step - loss: 0.4037 - categorical_accuracy: 0.8583 - accuracy: 0.8583 - val_loss: 0.7911 - val_categorical_accuracy: 0.6000 - val_accuracy: 0.6000\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.4271 - categorical_accuracy: 0.8333 - accuracy: 0.8333 - val_loss: 0.7354 - val_categorical_accuracy: 0.6000 - val_accuracy: 0.6000\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.3915 - categorical_accuracy: 0.8750 - accuracy: 0.8750 - val_loss: 0.6829 - val_categorical_accuracy: 0.7000 - val_accuracy: 0.7000\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.3495 - categorical_accuracy: 0.8667 - accuracy: 0.8667 - val_loss: 0.6547 - val_categorical_accuracy: 0.6333 - val_accuracy: 0.6333\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.3383 - categorical_accuracy: 0.8833 - accuracy: 0.8833 - val_loss: 0.6402 - val_categorical_accuracy: 0.6333 - val_accuracy: 0.6333\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.3129 - categorical_accuracy: 0.9083 - accuracy: 0.9083 - val_loss: 0.6136 - val_categorical_accuracy: 0.6667 - val_accuracy: 0.6667\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.2136 - categorical_accuracy: 0.9500 - accuracy: 0.9500 - val_loss: 0.6070 - val_categorical_accuracy: 0.7333 - val_accuracy: 0.7333\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.2712 - categorical_accuracy: 0.9167 - accuracy: 0.9167 - val_loss: 0.5979 - val_categorical_accuracy: 0.7333 - val_accuracy: 0.7333\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.2755 - categorical_accuracy: 0.8917 - accuracy: 0.8917 - val_loss: 0.5660 - val_categorical_accuracy: 0.7333 - val_accuracy: 0.7333\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.2775 - categorical_accuracy: 0.9000 - accuracy: 0.9000 - val_loss: 0.5372 - val_categorical_accuracy: 0.7333 - val_accuracy: 0.7333\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.1711 - categorical_accuracy: 0.9500 - accuracy: 0.9500 - val_loss: 0.5179 - val_categorical_accuracy: 0.7667 - val_accuracy: 0.7667\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.1793 - categorical_accuracy: 0.9750 - accuracy: 0.9750 - val_loss: 0.5119 - val_categorical_accuracy: 0.7667 - val_accuracy: 0.7667\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.2476 - categorical_accuracy: 0.9167 - accuracy: 0.9167 - val_loss: 0.4981 - val_categorical_accuracy: 0.8333 - val_accuracy: 0.8333\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.1715 - categorical_accuracy: 0.9583 - accuracy: 0.9583 - val_loss: 0.4827 - val_categorical_accuracy: 0.8667 - val_accuracy: 0.8667\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.1688 - categorical_accuracy: 0.9667 - accuracy: 0.9667 - val_loss: 0.4773 - val_categorical_accuracy: 0.8000 - val_accuracy: 0.8000\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.1820 - categorical_accuracy: 0.9500 - accuracy: 0.9500 - val_loss: 0.4756 - val_categorical_accuracy: 0.7667 - val_accuracy: 0.7667\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.1559 - categorical_accuracy: 0.9750 - accuracy: 0.9750 - val_loss: 0.4600 - val_categorical_accuracy: 0.8333 - val_accuracy: 0.8333\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 11s 3s/step - loss: 0.2032 - categorical_accuracy: 0.9250 - accuracy: 0.9250 - val_loss: 0.4525 - val_categorical_accuracy: 0.8333 - val_accuracy: 0.8333\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.1399 - categorical_accuracy: 0.9667 - accuracy: 0.9667 - val_loss: 0.4470 - val_categorical_accuracy: 0.8333 - val_accuracy: 0.8333\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 10s 3s/step - loss: 0.1794 - categorical_accuracy: 0.9667 - accuracy: 0.9667 - val_loss: 0.4524 - val_categorical_accuracy: 0.8667 - val_accuracy: 0.8667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oVG4pC57Q9vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4p_1LbVZQ-kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_data = test_datagen.flow_from_directory(predict_dir,\n",
        "                                             target_size = (image_size, image_size),\n",
        "                                            \n",
        "                                             class_mode = \"categorical\")"
      ],
      "metadata": {
        "id": "PMw_aVGtsZ5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7daf93a6-82b1-4aca-d845-d72800558350"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(predict_data)"
      ],
      "metadata": {
        "id": "XDZgCDumtFnj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result =  np.argmax(prediction, axis=1)\n",
        "result"
      ],
      "metadata": {
        "id": "aNOsClrstmlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8f986b-c5f6-4066-9e72-7f6c64cf35e3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 2, 1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories"
      ],
      "metadata": {
        "id": "dxnCssUVvxRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77de4a5f-6c40-4824-bd8d-5963f9333814"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bac', 'healthy', 'late']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "id": "M5zMjxJh3xve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ecd275-f39c-4d64-b740-6504163b85db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.42234984, 0.34608877, 0.23156139],\n",
              "       [0.13933934, 0.6658044 , 0.1948563 ],\n",
              "       [0.5099846 , 0.22664697, 0.2633684 ],\n",
              "       [0.41153347, 0.2651168 , 0.32334974],\n",
              "       [0.58843076, 0.31017166, 0.10139754],\n",
              "       [0.27168807, 0.34368157, 0.38463035],\n",
              "       [0.29331493, 0.58711946, 0.1195656 ],\n",
              "       [0.82451564, 0.10682069, 0.06866371],\n",
              "       [0.4482451 , 0.38604406, 0.16571087],\n",
              "       [0.29930153, 0.4553745 , 0.24532396]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data,\n",
        "                    validation_data=test_data,\n",
        "                    epochs=epochs,\n",
        "                    #steps_per_epoch = 100,\n",
        "                   # validation_steps = 100)"
      ],
      "metadata": {
        "id": "m40CVI5sOT3O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}